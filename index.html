<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Tianjian Feng | ZJU</title>
    <style>
      body {
        font-family:
          -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial,
          sans-serif;
        line-height: 1.6;
        color: #333;
        max-width: 800px;
        margin: 40px auto;
        padding: 0 20px;
      }
      h1 {
        font-size: 2.2em;
        margin-bottom: 0.2em;
      }
      h2 {
        border-bottom: 1px solid #eee;
        padding-bottom: 10px;
        margin-top: 40px;
      }
      .links a {
        margin-right: 15px;
        color: #007bff;
        text-decoration: none;
        font-weight: bold;
      }
      .pub-item {
        margin-bottom: 25px;
      }
      .pub-title {
        font-weight: bold;
        font-size: 1.1em;
      }
      .authors {
        font-size: 0.95em;
        color: #555;
      }
      .venue {
        font-style: italic;
        color: #888;
      }
      b {
        color: #000;
      }
    </style>
  </head>
  <body>
    <h1>Tianjian Feng</h1>
    <p>Junior CS Student @ Zhejiang University</p>

    <div class="links">
      <a href="mailto:ftj072514@gmail.com">Email</a>
      <a href="CV_Tianjian_Feng.pdf">CV [PDF]</a>
      <a href="https://github.com/Ftj072514">GitHub</a>
    </div>

    <h2>Research Interests</h2>
    <p>
      My research focuses on scaling and optimizing generative foundations
      across modalities. I am particularly interested in enhancing the spatial
      consistency, logical reasoning, and controllability of large-scale models
      (e.g., DiTs and DLMs) by innovating at the intersection of sampling-stage
      trajectory search and revisable latent representations. My goal is to
      develop high-fidelity, zero-shot generative frameworks that maintain
      structural and semantic integrity while enabling complex cross-modal
      manipulation.
    </p>

    <h2>Publications & Preprints</h2>
    <div class="pub-item">
      <div class="pub-title">
        TINKER: Diffusion's Gift to 3D--Multi-View Consistent Editing From
        Sparse Inputs without Per-Scene Optimization
      </div>
      <div class="authors">
        Canyu Zhao*, Xiaoman Li*, <b>Tianjian Feng</b>, Zhiyue Zhao, Hao Chen,
        Chunhua Shen
      </div>
      <div class="venue">Accepted at ICLR 2026</div>
      <a href="https://arxiv.org/abs/2508.14811">[Arxiv]</a>
      <a href="https://aim-uofa.github.io/Tinker/">[Project Page]</a>
    </div>

    <div class="pub-item">
      <div class="pub-title">
        Improving Diffusion Language Model Decoding through Joint Search in
        Generation Order and Token Space
      </div>
      <div class="authors">
        Yangyi Shen*, <b>Tianjian Feng*</b>, Jiaqi Han, Wen Wang, Tianlang Chen,
        Chunhua Shen, Jure Leskovec, Stefano Ermon
      </div>
      <div class="venue">arXiv Preprint</div>
      <a href="https://arxiv.org/abs/2601.20339">[Arxiv]</a>
    </div>

    <div class="pub-item">
      <div class="pub-title">
        Beyond Hard Masks: Progressive Token Evolution for Diffusion Language
        Models
      </div>
      <div class="authors">
        Linhao Zhong*, Linyu Wu*, Bozhen Fang, <b>Tianjian Feng</b>, Chenchen
        Jing, Wen Wang, Jiaheng Zhang, Hao Chen, Chunhua Shen
      </div>
      <div class="venue">arXiv Preprint</div>
      <a href="https://arxiv.org/abs/2601.07351">[Arxiv]</a>
      <a href="https://aim-uofa.github.io/EvoTokenDLM/">[Project Page]</a>
    </div>
  </body>
</html>
